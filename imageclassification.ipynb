{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments 1 and 2, general and transfer image classification tasks: binary image classification tasks A, B, and C, with full training and transfer learning / frozen weights (Fig 3)"
      ],
      "metadata": {
        "id": "fh6lPei0rq-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RLJF3R41eFA"
      },
      "outputs": [],
      "source": [
        "# To run the notebook, change the string below\n",
        "dir_path = '/path/to/my/directory'\n",
        "\n",
        "# Uncomment to run in Google Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(dir_path)\n",
        "\n",
        "# ViT model based on https://github.com/facebookresearch/dino/blob/main/README.md\n",
        "import importlib\n",
        "import torch\n",
        "import torch.random\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import vision_transformer\n",
        "import fnmatch\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# IMAGE CLASSIFICATION A, B, AND C DATA LOADERS\n",
        "\n",
        "traindirA = dir_path+\"/data/train/classificationA\"\n",
        "valdirA = dir_path+\"/data/val/classificationA\"\n",
        "\n",
        "traindirB = dir_path+\"/data/train/classificationB\"\n",
        "valdirB = dir_path+\"/data/val/classificationB\"\n",
        "\n",
        "traindirC = dir_path+\"/data/train/classificationC\"\n",
        "valdirC = dir_path+\"/data/val/classificationC\"\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])\n",
        "val_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      ])\n",
        "\n",
        "\n",
        "def schematrain(model, x, y, optimizer):\n",
        "    pred_attn, h1m, policy = model.forward(x)\n",
        "    mse = torch.nn.MSELoss()\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    pred_loss = 0.05*mse(pred_attn, h1m)\n",
        "    policy_loss = bce(policy, y)\n",
        "    total_loss = sum([pred_loss, policy_loss])\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return total_loss\n",
        "\n",
        "def schematrain_policy(model, x, y, optimizer):\n",
        "    pred_attn, h1m, policy = model.forward(x)\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    policy_loss = bce(policy, y)\n",
        "    policy_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return policy_loss\n",
        "\n",
        "def controltrain(model, x, y, optimizer):\n",
        "    h1, policy = model.forward(x)\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    policy_loss = bce(policy, y)\n",
        "    policy_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return policy_loss\n",
        "\n",
        "def fitschema(model, trainloader, valloader, name=\"\", n_epochs=20, policy_only=False):\n",
        "  bce = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "  losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  epoch_train_losses = []\n",
        "  epoch_val_losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      epoch_loss = 0\n",
        "      for i, data in enumerate(trainloader): # iterate over batches\n",
        "          x_batch, y_batch = data\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          model.train()\n",
        "          if policy_only:\n",
        "            loss = schematrain_policy(model, x_batch, y_batch, optimizer)\n",
        "          else:\n",
        "            loss = schematrain(model, x_batch, y_batch, optimizer)\n",
        "          epoch_loss += loss.item()/len(trainloader)\n",
        "          losses.append(loss.item())\n",
        "          if epoch == 0:\n",
        "            print(str(i)+\": \"+str(loss.item())+\" / \"+str(len(trainloader))+\": \"+str(epoch_loss))\n",
        "      epoch_train_losses.append(epoch_loss)\n",
        "      print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
        "      with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in valloader:\n",
        "          x_batch = x_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          y_batch = y_batch.to(device)\n",
        "\n",
        "          model.eval()\n",
        "\n",
        "          _, _, policy = model(x_batch)\n",
        "          val_loss = bce(policy,y_batch)\n",
        "          total_loss += val_loss.item()/len(valloader)\n",
        "          val_losses.append(val_loss.item())\n",
        "\n",
        "        epoch_val_losses.append(total_loss)\n",
        "        print('Epoch : {}, val loss : {}'.format(epoch+1,total_loss))\n",
        "\n",
        "        best_loss = min(epoch_val_losses)\n",
        "\n",
        "        # save best model\n",
        "        if total_loss <= best_loss:\n",
        "          best_model_wts = model.state_dict()\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "def fitcontrol(model, trainloader, valloader, name=\"\", n_epochs=20):\n",
        "  bce = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "  losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  epoch_train_losses = []\n",
        "  epoch_val_losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      epoch_loss = 0\n",
        "      for i, data in enumerate(trainloader): # iterate over batches\n",
        "          x_batch, y_batch = data\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          model.train()\n",
        "          loss = controltrain(model, x_batch, y_batch, optimizer)\n",
        "          epoch_loss += loss.item()/len(trainloader)\n",
        "          losses.append(loss.item())\n",
        "          if epoch == 0:\n",
        "            print(str(i)+\": \"+str(loss.item())+\" / \"+str(len(trainloader))+\": \"+str(epoch_loss))\n",
        "      epoch_train_losses.append(epoch_loss)\n",
        "      print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
        "      with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in valloader:\n",
        "          x_batch = x_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          y_batch = y_batch.to(device)\n",
        "\n",
        "          model.eval()\n",
        "\n",
        "          _, policy = model(x_batch)\n",
        "          val_loss = bce(policy,y_batch)\n",
        "          total_loss += val_loss.item()/len(valloader)\n",
        "          val_losses.append(val_loss.item())\n",
        "\n",
        "        epoch_val_losses.append(total_loss)\n",
        "        print('Epoch : {}, val loss : {}'.format(epoch+1,total_loss))\n",
        "\n",
        "        best_loss = min(epoch_val_losses)\n",
        "\n",
        "        # save best model\n",
        "        if total_loss <= best_loss:\n",
        "          best_model_wts = model.state_dict()\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "def evaluate(model, valloader, name=\"\", save_attn=False):\n",
        "  classifications = []\n",
        "  labels = []\n",
        "  model.eval()\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  total_acc = 0\n",
        "  for i, data in enumerate(valloader):\n",
        "      accuracy = 0\n",
        "      x_batch, y_batch = data\n",
        "      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "      y_batch = y_batch.unsqueeze(1).float()\n",
        "      outputs = model.forward(x_batch)\n",
        "      policy = outputs[-1]\n",
        "      policy = torch.round(sigmoid(policy))\n",
        "      accuracy = 1-(torch.sum(abs(policy - y_batch))/len(y_batch))\n",
        "      total_acc += accuracy.item()/len(valloader)\n",
        "      for pol in policy:\n",
        "        classifications.append(pol.item())\n",
        "      for yb in y_batch:\n",
        "        labels.append(yb.item())\n",
        "\n",
        "  file = open(dir_path+\"/accuracy_\"+name+\".txt\",\"w\")\n",
        "  file.write(str(total_acc))\n",
        "  file.close()\n",
        "\n",
        "def freeze_models(models):\n",
        "  for i, model in enumerate(models):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.policy.parameters():\n",
        "        param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seedn = 0\n",
        "seeds = [43250, 58038, 70991, 85884, 88252, 98122, 59732, 59721, 34361,\n",
        "         24375, 17167, 25532, 24606, 27055, 77062, 27850, 93109, 37718,\n",
        "         70332, 75087]\n",
        "\n",
        "for trial in range(0,20):\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "  tname = \"trial\"+str(trial)\n",
        "  # FIT / EVALUATE MODELS: IMAGE CLASSIFICATION\n",
        "  # A\n",
        "  train_dataA = datasets.ImageFolder(traindirA,transform=train_transforms)\n",
        "  val_dataA = datasets.ImageFolder(valdirA,transform=val_transforms)\n",
        "\n",
        "  trainloaderA = torch.utils.data.DataLoader(train_dataA, shuffle = True, batch_size=8)\n",
        "  valloaderA = torch.utils.data.DataLoader(val_dataA, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelAschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelAcontrol = vision_transformer.VitControl().to(device)\n",
        "\n",
        "  fitschema(modelAschema, trainloaderA, valloaderA, tname+\"A\")\n",
        "  evaluate(modelAschema, valloaderA, tname+\"Aschema\", save_attn=False)\n",
        "  fitcontrol(modelAcontrol, trainloaderA, valloaderA, tname+\"A\")\n",
        "  evaluate(modelAcontrol, valloaderA, tname+\"Acontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataA)\n",
        "  del(val_dataA)\n",
        "  del(trainloaderA)\n",
        "  del(valloaderA)\n",
        "\n",
        "\n",
        "  # B\n",
        "  train_dataB = datasets.ImageFolder(traindirB,transform=train_transforms)\n",
        "  val_dataB = datasets.ImageFolder(valdirB,transform=val_transforms)\n",
        "\n",
        "  trainloaderB = torch.utils.data.DataLoader(train_dataB, shuffle = True, batch_size=8)\n",
        "  valloaderB = torch.utils.data.DataLoader(val_dataB, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelBschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelBcontrol = vision_transformer.VitControl().to(device)\n",
        "\n",
        "  fitschema(modelBschema, trainloaderB, valloaderB, tname+\"B\")\n",
        "  evaluate(modelBschema, valloaderB, tname+\"Bschema\", save_attn=False)\n",
        "  fitcontrol(modelBcontrol, trainloaderB, valloaderB, tname+\"B\")\n",
        "  evaluate(modelBcontrol, valloaderB, tname+\"Bcontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataB)\n",
        "  del(val_dataB)\n",
        "  del(trainloaderB)\n",
        "  del(valloaderB)\n",
        "\n",
        "  # C\n",
        "  train_dataC = datasets.ImageFolder(traindirC,transform=train_transforms)\n",
        "  val_dataC = datasets.ImageFolder(valdirC,transform=val_transforms)\n",
        "\n",
        "  trainloaderC = torch.utils.data.DataLoader(train_dataC, shuffle = True, batch_size=8)\n",
        "  valloaderC = torch.utils.data.DataLoader(val_dataC, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelCschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelCcontrol = vision_transformer.VitControl().to(device)\n",
        "\n",
        "  fitschema(modelCschema, trainloaderC, valloaderC, tname+\"C\")\n",
        "  evaluate(modelCschema, valloaderC, tname+\"Cschema\", save_attn=False)\n",
        "  fitcontrol(modelCcontrol, trainloaderC, valloaderC, tname+\"C\")\n",
        "  evaluate(modelCcontrol, valloaderC, tname+\"Ccontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataC)\n",
        "  del(val_dataC)\n",
        "  del(trainloaderC)\n",
        "  del(valloaderC)\n",
        "\n",
        "  # FREEZE THE MODELS\n",
        "  freeze_models([modelAschema, modelAcontrol, modelBschema, modelBcontrol, modelCschema, modelCcontrol])\n",
        "\n",
        "  # TRANSFER LEARNING\n",
        "  train_dataB = datasets.ImageFolder(traindirB,transform=train_transforms)\n",
        "  val_dataB = datasets.ImageFolder(valdirB,transform=val_transforms)\n",
        "\n",
        "  trainloaderB = torch.utils.data.DataLoader(train_dataB, shuffle = True, batch_size=8)\n",
        "  valloaderB = torch.utils.data.DataLoader(val_dataB, shuffle = True, batch_size=8)\n",
        "\n",
        "  fitschema(modelAschema, trainloaderB, valloaderB, tname+\"AschemaB\", policy_only=True)\n",
        "  evaluate(modelAschema, valloaderB, tname+\"AschemaB\")\n",
        "\n",
        "  fitcontrol(modelAcontrol, trainloaderB, valloaderB, tname+\"AcontrolB\")\n",
        "  evaluate(modelAschema, valloaderB, tname+\"AcontrolB\")\n",
        "\n",
        "  del(train_dataB)\n",
        "  del(val_dataB)\n",
        "  del(trainloaderB)\n",
        "  del(valloaderB)\n",
        "\n",
        "  del(modelAschema)\n",
        "  del(modelAcontrol)\n",
        "\n",
        "  train_dataC = datasets.ImageFolder(traindirC,transform=train_transforms)\n",
        "  val_dataC = datasets.ImageFolder(valdirC,transform=val_transforms)\n",
        "\n",
        "  trainloaderC = torch.utils.data.DataLoader(train_dataC, shuffle = True, batch_size=8)\n",
        "  valloaderC = torch.utils.data.DataLoader(val_dataC, shuffle = True, batch_size=8)\n",
        "\n",
        "  fitschema(modelBschema, trainloaderC, valloaderC, tname+\"BschemaC\", policy_only=True)\n",
        "  evaluate(modelBschema, valloaderC, tname+\"BschemaC\")\n",
        "\n",
        "  fitcontrol(modelBcontrol, trainloaderC, valloaderC, tname+\"BcontrolC\")\n",
        "  evaluate(modelBcontrol, valloaderC, tname+\"BcontrolC\")\n",
        "\n",
        "  del(train_dataC)\n",
        "  del(val_dataC)\n",
        "  del(trainloaderC)\n",
        "  del(valloaderC)\n",
        "\n",
        "  del(modelBschema)\n",
        "  del(modelBcontrol)\n",
        "\n",
        "  train_dataA = datasets.ImageFolder(traindirA,transform=train_transforms)\n",
        "  val_dataA = datasets.ImageFolder(valdirA,transform=val_transforms)\n",
        "\n",
        "  trainloaderA = torch.utils.data.DataLoader(train_dataA, shuffle = True, batch_size=8)\n",
        "  valloaderA = torch.utils.data.DataLoader(val_dataA, shuffle = True, batch_size=8)\n",
        "\n",
        "  fitschema(modelCschema, trainloaderA, valloaderA, tname+\"CschemaA\", policy_only=True)\n",
        "  evaluate(modelCschema, valloaderA, tname+\"CschemaA\")\n",
        "\n",
        "  fitcontrol(modelCcontrol, trainloaderA, valloaderA, tname+\"CcontrolA\")\n",
        "  evaluate(modelCcontrol, valloaderA, tname+\"CcontrolA\")\n",
        "\n",
        "  del(train_dataA)\n",
        "  del(val_dataA)\n",
        "  del(trainloaderA)\n",
        "  del(valloaderA)\n",
        "\n",
        "  del(modelCschema)\n",
        "  del(modelCcontrol)\n",
        "\n",
        "  seedn += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "wvGJaXMs5v25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}