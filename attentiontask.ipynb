{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1: the discrimination of genuine and artificially shuffled full attentional vectors (Fig 2)"
      ],
      "metadata": {
        "id": "F7hAcakInyRk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RLJF3R41eFA"
      },
      "outputs": [],
      "source": [
        "# To run the notebook, change the string below\n",
        "dir_path = '/path/to/my/directory'\n",
        "\n",
        "# Uncomment to run in Google Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(dir_path)\n",
        "\n",
        "# ViT model based on https://github.com/facebookresearch/dino/blob/main/README.md\n",
        "import importlib\n",
        "import torch\n",
        "import torch.random\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import vision_transformer\n",
        "import fnmatch\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# IMAGE CLASSIFICATION A, B, AND C DATA LOADERS\n",
        "\n",
        "traindirA = dir_path+\"/data/train/classificationA\"\n",
        "valdirA = dir_path+\"/data/val/classificationA\"\n",
        "\n",
        "traindirB = dir_path+\"/data/train/classificationB\"\n",
        "valdirB = dir_path+\"/data/val/classificationB\"\n",
        "\n",
        "traindirC = dir_path+\"/data/train/classificationC\"\n",
        "valdirC = dir_path+\"/data/val/classificationC\"\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])\n",
        "val_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      ])\n",
        "\n",
        "\n",
        "def schematrain(model, x, y, optimizer):\n",
        "    pred_attn, h1m, policy = model.forward(x)\n",
        "    mse = torch.nn.MSELoss()\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    pred_loss = 0.05*mse(pred_attn, h1m)\n",
        "    policy_loss = bce(policy, y)\n",
        "    total_loss = sum([pred_loss, policy_loss])\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return total_loss\n",
        "\n",
        "def schematrain_policy(model, x, y, optimizer):\n",
        "    pred_attn, h1m, policy = model.forward(x)\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    policy_loss = bce(policy, y)\n",
        "    policy_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return policy_loss\n",
        "\n",
        "def controltrain(model, x, y, optimizer):\n",
        "    h1, policy = model.forward(x)\n",
        "    bce = torch.nn.BCEWithLogitsLoss()\n",
        "    policy_loss = bce(policy, y)\n",
        "    policy_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return policy_loss\n",
        "\n",
        "def fitschema(model, trainloader, valloader, name=\"\", n_epochs=20, policy_only=False):\n",
        "  bce = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "  losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  epoch_train_losses = []\n",
        "  epoch_val_losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      epoch_loss = 0\n",
        "      for i, data in enumerate(trainloader): # iterate over batches\n",
        "          x_batch, y_batch = data\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          model.train()\n",
        "          if policy_only:\n",
        "            loss = schematrain_policy(model, x_batch, y_batch, optimizer)\n",
        "          else:\n",
        "            loss = schematrain(model, x_batch, y_batch, optimizer)\n",
        "          epoch_loss += loss.item()/len(trainloader)\n",
        "          losses.append(loss.item())\n",
        "          if epoch == 0:\n",
        "            print(str(i)+\": \"+str(loss.item())+\" / \"+str(len(trainloader))+\": \"+str(epoch_loss))\n",
        "      epoch_train_losses.append(epoch_loss)\n",
        "      print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
        "      with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in valloader:\n",
        "          x_batch = x_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float()\n",
        "          y_batch = y_batch.to(device)\n",
        "\n",
        "          model.eval()\n",
        "\n",
        "          _, _, policy = model(x_batch)\n",
        "          val_loss = bce(policy,y_batch)\n",
        "          total_loss += val_loss.item()/len(valloader)\n",
        "          val_losses.append(val_loss.item())\n",
        "\n",
        "        epoch_val_losses.append(total_loss)\n",
        "        print('Epoch : {}, val loss : {}'.format(epoch+1,total_loss))\n",
        "\n",
        "        best_loss = min(epoch_val_losses)\n",
        "\n",
        "        # save best model\n",
        "        if total_loss <= best_loss:\n",
        "          best_model_wts = model.state_dict()\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "def fitcontrol(model, trainloader, valloader, name=\"\", n_epochs=20):\n",
        "  bce = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "  losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  epoch_train_losses = []\n",
        "  epoch_val_losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      epoch_loss = 0\n",
        "      for i, data in enumerate(trainloader): #iterate over batches\n",
        "          x_batch, y_batch = data\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
        "          model.train()\n",
        "          loss = controltrain(model, x_batch, y_batch, optimizer)\n",
        "          epoch_loss += loss.item()/len(trainloader)\n",
        "          losses.append(loss.item())\n",
        "          if epoch == 0:\n",
        "            print(str(i)+\": \"+str(loss.item())+\" / \"+str(len(trainloader))+\": \"+str(epoch_loss))\n",
        "      epoch_train_losses.append(epoch_loss)\n",
        "      print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
        "      with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in valloader:\n",
        "          x_batch = x_batch.to(device)\n",
        "          y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
        "          y_batch = y_batch.to(device)\n",
        "\n",
        "          #model to eval mode\n",
        "          model.eval()\n",
        "\n",
        "          _, policy = model(x_batch)\n",
        "          val_loss = bce(policy,y_batch)\n",
        "          total_loss += val_loss.item()/len(valloader)\n",
        "          val_losses.append(val_loss.item())\n",
        "\n",
        "        epoch_val_losses.append(total_loss)\n",
        "        print('Epoch : {}, val loss : {}'.format(epoch+1,total_loss))\n",
        "\n",
        "        best_loss = min(epoch_val_losses)\n",
        "\n",
        "        #save best model\n",
        "        if total_loss <= best_loss:\n",
        "          best_model_wts = model.state_dict()\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "def evaluate(model, valloader, name=\"\", save_attn=False):\n",
        "  classifications = []\n",
        "  labels = []\n",
        "  model.eval()\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  total_acc = 0\n",
        "  for i, data in enumerate(valloader):\n",
        "      accuracy = 0\n",
        "      x_batch, y_batch = data\n",
        "      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "      y_batch = y_batch.unsqueeze(1).float()\n",
        "      outputs = model.forward(x_batch)\n",
        "      policy = outputs[-1]\n",
        "      policy = torch.round(sigmoid(policy))\n",
        "      accuracy = 1-(torch.sum(abs(policy - y_batch))/len(y_batch))\n",
        "      total_acc += accuracy.item()/len(valloader)\n",
        "      for pol in policy:\n",
        "        classifications.append(pol.item())\n",
        "      for yb in y_batch:\n",
        "        labels.append(yb.item())\n",
        "\n",
        "  file = open(dir_path+\"/accuracy_\"+name+\".txt\",\"w\")\n",
        "  file.write(str(total_acc))\n",
        "  file.close()\n",
        "\n",
        "def freeze_models(models):\n",
        "  for i, model in enumerate(models):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.policy.parameters():\n",
        "        param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wvGJaXMs5v25"
      },
      "outputs": [],
      "source": [
        "seedn = 0\n",
        "seeds = [72442,16007,15137,96512,19047,59485,75241,95430,72796,63453,26884,53675,\n",
        "         18008,15186,27656,31995,93321,89984,29108,75579,35223,13737,92478,17877,\n",
        "         68783,67243,71062,45080,43868,38000,73096,51761,64413,62026,50615,23993,\n",
        "         50152,22721,92064,87461,97294,59936,14695,15888,48874,37701,27120,60244,\n",
        "         97999,73735,81996,72191,77250,50393,23720,63282,19530,45563,98929,14856,\n",
        "         78783,75455,55985,89396,74140,74802,58912,14247,13741,41605,94482,20021,\n",
        "         94900,54095,56975,57805,76423,58744,22887,62985,29424,58566,19647,65836,\n",
        "         49274,99511,81839,78935,29560,97097,85628,87836,69055,19863,38173,80205,\n",
        "         25417,79727,92203,69116]\n",
        "\n",
        "for trial in range(11):\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "  tname = \"trial\"+str(trial)\n",
        "\n",
        "  # FIT / EVALUATE MODELS: IMAGE CLASSIFICATION\n",
        "  # A\n",
        "  train_dataA = datasets.ImageFolder(traindirA,transform=train_transforms)\n",
        "  val_dataA = datasets.ImageFolder(valdirA,transform=val_transforms)\n",
        "\n",
        "  trainloaderA = torch.utils.data.DataLoader(train_dataA, shuffle = True, batch_size=8)\n",
        "  valloaderA = torch.utils.data.DataLoader(val_dataA, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelAschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelAcontrol = vision_transformer.VitControl().to(device)\n",
        "\n",
        "  fitschema(modelAschema, trainloaderA, valloaderA, tname+\"A\")\n",
        "  fitcontrol(modelAcontrol, trainloaderA, valloaderA, tname+\"A\")\n",
        "\n",
        "  evaluate(modelAschema, valloaderA, tname+\"Aschema\", save_attn=False)\n",
        "  evaluate(modelAcontrol, valloaderA, tname+\"Acontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataA)\n",
        "  del(val_dataA)\n",
        "  del(trainloaderA)\n",
        "  del(valloaderA)\n",
        "\n",
        "  # B\n",
        "  train_dataB = datasets.ImageFolder(traindirB,transform=train_transforms)\n",
        "  val_dataB = datasets.ImageFolder(valdirB,transform=val_transforms)\n",
        "\n",
        "  trainloaderB = torch.utils.data.DataLoader(train_dataB, shuffle = True, batch_size=8)\n",
        "  valloaderB = torch.utils.data.DataLoader(val_dataB, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelBschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelBcontrol = vision_transformer.VitControl().to(device)\n",
        "\n",
        "  fitschema(modelBschema, trainloaderB, valloaderB, tname+\"B\")\n",
        "  fitcontrol(modelBcontrol, trainloaderB, valloaderB, tname+\"B\")\n",
        "\n",
        "  evaluate(modelBschema, valloaderB, tname+\"Bschema\", save_attn=False)\n",
        "  evaluate(modelBcontrol, valloaderB, tname+\"Bcontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataB)\n",
        "  del(val_dataB)\n",
        "  del(trainloaderB)\n",
        "  del(valloaderB)\n",
        "\n",
        "  # C\n",
        "  train_dataC = datasets.ImageFolder(traindirC,transform=train_transforms)\n",
        "  val_dataC = datasets.ImageFolder(valdirC,transform=val_transforms)\n",
        "\n",
        "  trainloaderC = torch.utils.data.DataLoader(train_dataC, shuffle = True, batch_size=8)\n",
        "  valloaderC = torch.utils.data.DataLoader(val_dataC, shuffle = True, batch_size=8)\n",
        "\n",
        "  modelCschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelCcontrol = vision_transformer.VitControl().to(device)\n",
        "  fitschema(modelCschema, trainloaderC, valloaderC, tname+\"C\")\n",
        "  fitcontrol(modelCcontrol, trainloaderC, valloaderC, tname+\"C\")\n",
        "\n",
        "  evaluate(modelCschema, valloaderC, tname+\"Cschema\", save_attn=False)\n",
        "  evaluate(modelCcontrol, valloaderC, tname+\"Ccontrol\", save_attn=False)\n",
        "\n",
        "  del(train_dataC)\n",
        "  del(val_dataC)\n",
        "  del(trainloaderC)\n",
        "  del(valloaderC)\n",
        "\n",
        "  # FREEZE THE MODELS\n",
        "  freeze_models([modelAschema, modelAcontrol, modelBschema, modelBcontrol, modelCschema, modelCcontrol])\n",
        "\n",
        "  modelAschema_wts = deepcopy(modelAschema.state_dict())\n",
        "  modelAcontrol_wts = deepcopy(modelAcontrol.state_dict())\n",
        "  modelBschema_wts = deepcopy(modelBschema.state_dict())\n",
        "  modelBcontrol_wts = deepcopy(modelBcontrol.state_dict())\n",
        "  modelCschema_wts = deepcopy(modelCschema.state_dict())\n",
        "  modelCcontrol_wts = deepcopy(modelCcontrol.state_dict())\n",
        "\n",
        "  # FIT / EVALUATE MODELS: ATTENTION CLASSIFICATION\n",
        "  # SCHEMA\n",
        "  batch_size = 8\n",
        "  attn_transforms = transforms.Resize((256,256))\n",
        "\n",
        "  schemaAattn = torch.load(dir_path+\"/data/attentions/modelAschemaattn.pt\")\n",
        "  schemaAattn = attn_transforms(schemaAattn)\n",
        "  false_schemaAattn = torch.clone(schemaAattn)\n",
        "  indices = torch.randperm(false_schemaAattn.shape[-1])\n",
        "  false_schemaAattn = false_schemaAattn[:,:,indices] # false attention values are shuffled along last dimension\n",
        "\n",
        "  dataset_schemaAattn = TensorDataset(torch.cat((schemaAattn, false_schemaAattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_schemaAattn = torch.utils.data.random_split(dataset_schemaAattn, [0.9, 0.1])\n",
        "  schemaAattntrain = DataLoader(dataset_schemaAattn[0], batch_size, shuffle=True)\n",
        "  schemaAattnval = DataLoader(dataset_schemaAattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitcontrol(modelCcontrol, schemaAattntrain, schemaAattnval, tname+\"CAcontrol_schemaattn\", n_epochs=800)\n",
        "  evaluate(modelCcontrol, schemaAattnval, tname+\"CAcontrol_schemaattn\", save_attn=False)\n",
        "  fitschema(modelCschema, schemaAattntrain, schemaAattnval, tname+\"CAschema_schemaattn\", n_epochs=800, policy_only=True)\n",
        "  evaluate(modelCschema, schemaAattnval, tname+\"CAschema_schemaattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(schemaAattn)\n",
        "  del(false_schemaAattn)\n",
        "  del(indices)\n",
        "  del(dataset_schemaAattn)\n",
        "  del(schemaAattntrain)\n",
        "  del(schemaAattnval)\n",
        "\n",
        "  schemaBattn = torch.load(dir_path+\"/data/attentions/modelBschemaattn.pt\")\n",
        "  schemaBattn = attn_transforms(schemaBattn)\n",
        "  false_schemaBattn = torch.clone(schemaBattn)\n",
        "  indices = torch.randperm(false_schemaBattn.shape[-1])\n",
        "  false_schemaBattn = false_schemaBattn[:,:,indices]\n",
        "\n",
        "  dataset_schemaBattn = TensorDataset(torch.cat((schemaBattn, false_schemaBattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_schemaBattn = torch.utils.data.random_split(dataset_schemaBattn, [0.9, 0.1])\n",
        "  schemaBattntrain = DataLoader(dataset_schemaBattn[0], batch_size, shuffle=True)\n",
        "  schemaBattnval = DataLoader(dataset_schemaBattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitschema(modelAschema, schemaBattntrain, schemaBattnval, tname+\"ABschema_schemaattn\", n_epochs=800, policy_only=True)\n",
        "  fitcontrol(modelAcontrol, schemaBattntrain, schemaBattnval, tname+\"ABcontrol_schemaattn\", n_epochs=800)\n",
        "\n",
        "  evaluate(modelAschema, schemaBattnval, tname+\"ABschema_schemaattn\", save_attn=False)\n",
        "  evaluate(modelAcontrol, schemaBattnval, tname+\"ABcontrol_schemaattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(schemaBattn)\n",
        "  del(false_schemaBattn)\n",
        "  del(indices)\n",
        "  del(dataset_schemaBattn)\n",
        "  del(schemaBattntrain)\n",
        "  del(schemaBattnval)\n",
        "\n",
        "  schemaCattn = torch.load(dir_path+\"/data/attentions/modelCschemaattn.pt\")\n",
        "  schemaCattn = attn_transforms(schemaCattn)\n",
        "  false_schemaCattn = torch.clone(schemaCattn)\n",
        "  indices = torch.randperm(false_schemaCattn.shape[-1])\n",
        "  false_schemaCattn = false_schemaCattn[:,:,indices]\n",
        "\n",
        "  dataset_schemaCattn = TensorDataset(torch.cat((schemaCattn, false_schemaCattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_schemaCattn = torch.utils.data.random_split(dataset_schemaCattn, [0.9, 0.1])\n",
        "  schemaCattntrain = DataLoader(dataset_schemaCattn[0], batch_size, shuffle=True)\n",
        "  schemaCattnval = DataLoader(dataset_schemaCattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitschema(modelBschema, schemaCattntrain, schemaCattnval, \"BCschema_schemaattn\", n_epochs=800, policy_only=True)\n",
        "  fitcontrol(modelBcontrol, schemaCattntrain, schemaCattnval, \"BCcontrol_schemaattn\", n_epochs=800)\n",
        "\n",
        "  evaluate(modelBschema, schemaCattnval, tname+\"BCschema_schemaattn\", save_attn=False)\n",
        "  evaluate(modelBcontrol, schemaCattnval, tname+\"BCcontrol_schemaattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(schemaCattn)\n",
        "  del(false_schemaCattn)\n",
        "  del(indices)\n",
        "  del(dataset_schemaCattn)\n",
        "  del(schemaCattntrain)\n",
        "  del(schemaCattnval)\n",
        "\n",
        "  # CONTROL\n",
        "  del(modelAschema)\n",
        "  del(modelAcontrol)\n",
        "  del(modelBschema)\n",
        "  del(modelBcontrol)\n",
        "  del(modelCschema)\n",
        "  del(modelCcontrol)\n",
        "\n",
        "  modelCschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelCcontrol = vision_transformer.VitControl().to(device)\n",
        "  modelCschema.load_state_dict(modelCschema_wts)\n",
        "  modelCcontrol.load_state_dict(modelCcontrol_wts)\n",
        "  freeze_models([modelCschema, modelCcontrol])\n",
        "\n",
        "  controlAattn = torch.load(dir_path+\"/data/attentions/modelAcontrolattn.pt\")\n",
        "  controlAattn = attn_transforms(controlAattn)\n",
        "  false_controlAattn = torch.clone(controlAattn)\n",
        "  indices = torch.randperm(false_controlAattn.shape[-1])\n",
        "  false_controlAattn = false_controlAattn[:,:,indices] # false attention values are shuffled along last dimension\n",
        "\n",
        "  dataset_controlAattn = TensorDataset(torch.cat((controlAattn, false_controlAattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_controlAattn = torch.utils.data.random_split(dataset_controlAattn, [0.9, 0.1])\n",
        "  controlAattntrain = DataLoader(dataset_controlAattn[0], batch_size, shuffle=True)\n",
        "  controlAattnval = DataLoader(dataset_controlAattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitschema(modelCschema, controlAattntrain, controlAattnval, tname+\"CAs_controlattn\", n_epochs=800, policy_only=True)\n",
        "  fitcontrol(modelCcontrol, controlAattntrain, controlAattnval, tname+\"CAc_controlattn\", n_epochs=800)\n",
        "\n",
        "  evaluate(modelCschema, controlAattnval, tname+\"CAschema_controlattn\", save_attn=False)\n",
        "  evaluate(modelCcontrol, controlAattnval, tname+\"CAcontrol_controlattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(controlAattn)\n",
        "  del(false_controlAattn)\n",
        "  del(indices)\n",
        "  del(dataset_controlAattn)\n",
        "  del(controlAattntrain)\n",
        "  del(controlAattnval)\n",
        "  del(modelCschema)\n",
        "  del(modelCcontrol)\n",
        "  del(modelCschema_wts)\n",
        "  del(modelCcontrol_wts)\n",
        "\n",
        "  modelAschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelAcontrol = vision_transformer.VitControl().to(device)\n",
        "  modelAschema.load_state_dict(modelAschema_wts)\n",
        "  modelAcontrol.load_state_dict(modelAcontrol_wts)\n",
        "  freeze_models([modelAschema, modelAcontrol])\n",
        "\n",
        "  controlBattn = torch.load(dir_path+\"/data/attentions/modelBcontrolattn.pt\")\n",
        "  controlBattn = attn_transforms(controlBattn)\n",
        "  false_controlBattn = torch.clone(controlBattn)\n",
        "  indices = torch.randperm(false_controlBattn.shape[-1])\n",
        "  false_controlBattn = false_controlBattn[:,:,indices]\n",
        "\n",
        "  dataset_controlBattn = TensorDataset(torch.cat((controlBattn, false_controlBattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_controlBattn = torch.utils.data.random_split(dataset_controlBattn, [0.9, 0.1])\n",
        "  controlBattntrain = DataLoader(dataset_controlBattn[0], batch_size, shuffle=True)\n",
        "  controlBattnval = DataLoader(dataset_controlBattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitschema(modelAschema, controlBattntrain, controlBattnval, tname+\"ABs_controlattn\", n_epochs=800, policy_only=True)\n",
        "  fitcontrol(modelAcontrol, controlBattntrain, controlBattnval, tname+\"ABc_controlattn\", n_epochs=800)\n",
        "\n",
        "  evaluate(modelAschema, controlBattnval, tname+\"ABschema_controlattn\", save_attn=False)\n",
        "  evaluate(modelAcontrol, controlBattnval, tname+\"ABcontrol_controlattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(controlBattn)\n",
        "  del(false_controlBattn)\n",
        "  del(indices)\n",
        "  del(dataset_controlBattn)\n",
        "  del(controlBattntrain)\n",
        "  del(controlBattnval)\n",
        "  del(modelAschema)\n",
        "  del(modelAcontrol)\n",
        "  del(modelAschema_wts)\n",
        "  del(modelAcontrol_wts)\n",
        "\n",
        "  modelBschema = vision_transformer.VitAttentionSchema().to(device)\n",
        "  modelBcontrol = vision_transformer.VitControl().to(device)\n",
        "  modelBschema.load_state_dict(modelBschema_wts)\n",
        "  modelBcontrol.load_state_dict(modelBcontrol_wts)\n",
        "  freeze_models([modelBschema, modelBcontrol])\n",
        "\n",
        "  controlCattn = torch.load(dir_path+\"/data/attentions/modelCcontrolattn.pt\")\n",
        "  controlCattn = attn_transforms(controlCattn)\n",
        "  false_controlCattn = torch.clone(controlCattn)\n",
        "  indices = torch.randperm(false_controlCattn.shape[-1])\n",
        "  false_controlCattn = false_controlCattn[:,:,indices]\n",
        "\n",
        "  dataset_controlCattn = TensorDataset(torch.cat((controlCattn, false_controlCattn),0),\n",
        "                                      torch.cat((torch.ones(730,), torch.zeros(730,)),0))\n",
        "  dataset_controlCattn = torch.utils.data.random_split(dataset_controlCattn, [0.9, 0.1])\n",
        "  controlCattntrain = DataLoader(dataset_controlCattn[0], batch_size, shuffle=True)\n",
        "  controlCattnval = DataLoader(dataset_controlCattn[1], batch_size, shuffle=True)\n",
        "\n",
        "  fitschema(modelBschema, controlCattntrain, controlCattnval, tname+\"BCs_controlattn\", n_epochs=800, policy_only=True)\n",
        "  fitcontrol(modelBcontrol, controlCattntrain, controlCattnval, tname+\"BCc_controlattn\", n_epochs=800)\n",
        "\n",
        "  evaluate(modelBschema, controlCattnval, tname+\"BCschema_controlattn\", save_attn=False)\n",
        "  evaluate(modelBcontrol, controlCattnval, tname+\"BCcontrol_controlattn\", save_attn=False)\n",
        "\n",
        "  seedn += 1\n",
        "  torch.manual_seed(seeds[seedn])\n",
        "\n",
        "  del(controlCattn)\n",
        "  del(false_controlCattn)\n",
        "  del(indices)\n",
        "  del(dataset_controlCattn)\n",
        "  del(controlCattntrain)\n",
        "  del(controlCattnval)\n",
        "  del(modelBschema)\n",
        "  del(modelBcontrol)\n",
        "  del(modelBschema_wts)\n",
        "  del(modelBcontrol_wts)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}